
ğŸ“¦ numlol ğŸ 

ğŸ’­ Class for neural nets
ğŸ’­ Code for reference: https://github.com/pangolulu/neural-network-from-scratch
ğŸŒ ğŸ‡ ğŸ•¸ ğŸ‡

   ğŸ’­ The weights of the different layers
   ğŸ–ğŸ†• W ğŸ¨ğŸšğŸğŸ†

   ğŸ’­ The biases of the different layers
   ğŸ–ğŸ†• b ğŸ¨ğŸšğŸğŸ†

   ğŸ’­ The dimensions of the various layers
   ğŸ–ğŸ†• layers_dim ğŸ¨ğŸšğŸ”¢ğŸ†

   ğŸ†• ğŸ¼ layers_dim ğŸ¨ğŸšğŸ”¢ğŸ† ğŸ‡
      ğŸ’­ Create empty lists for weights/biases
      ğŸ†•ğŸ¨ğŸšğŸğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– W
      ğŸ†•ğŸ¨ğŸšğŸğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– b
      ğŸ’­ Iterate over all layers and create random weights/biases
      ğŸ†• â©â© 0 ğŸ”layers_dimâ—â–1 â— â¡ï¸  range_layers
      ğŸ”‚ i ğŸ¡ range_layersâ—ï¸ğŸ‡
         ğŸ’­ Create weights for layer
         ğŸ”® ğŸ‡ğŸ ğŸ½ layers_dim iâ— ğŸ½ layers_dim iâ• 1â— -1.0 1.0â— â¡ï¸ random_W
         ğŸ’­ He initialisation
         1.0 â— â›· ğŸ’¯ ğŸ½ layers_dim iâ—â—â— â¡ï¸ he_factor
         ğŸ» W ğŸ¥ ğŸ‡ğŸ random_W he_factorâ—â—

         ğŸ’­ Create biases for layers
         ğŸ”® ğŸ‡ğŸ 1 ğŸ½ layers_dim iâ•1â—  -1.0 1.0â— â¡ï¸ random_b
         ğŸ» b random_bâ—
      ğŸ‰
   ğŸ‰

    ğŸ’­ Calculate loss ("Is this loss?")
   â—ğŸ¦– XğŸ yğŸ â¡ï¸ ğŸ ğŸ‡
      ğŸ†• â©â© 0 ğŸ” Wâ— â— â¡ï¸  range_W
      X â¡ï¸ğŸ– ğŸ†• input
      ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input
      ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
         ğŸ’­ğŸ¥ğŸ‡ğŸ inputğŸ½ W iâ—â— â¡ï¸ test
         ğŸ‹ğŸ‡ğŸ ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— ğŸ½ b iâ—â— â¡ï¸ raw_output
         ğŸ“¸ğŸ‡ğŸ raw_outputâ— â¡ï¸ ğŸ–input
      ğŸ‰
      â†©ï¸ ğŸ”ğŸ‡ğŸ ğŸ‘¬ğŸ‡ğŸ input ğŸ”ğŸ‡ğŸ yâ—â—â—
   ğŸ‰

   ğŸ’­ Make prediction
   â—ğŸ¦• XğŸ â¡ï¸ ğŸ ğŸ‡
      ğŸ†• â©â© 0 ğŸ” Wâ— â— â¡ï¸  range_W
      X â¡ï¸ğŸ– ğŸ†• input
      ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input
      ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
         ğŸ‹ğŸ‡ğŸ ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— ğŸ½ b iâ—â— â¡ï¸ raw_output
         ğŸ“¸ğŸ‡ğŸ raw_outputâ— â¡ï¸ ğŸ–input
      ğŸ‰
      â†©ï¸ ğŸ”ğŸ‡ğŸ inputâ—
   ğŸ‰

   ğŸ’­ Train the net
   â—ğŸ¦„ XğŸ yğŸ epochsğŸ”¢ learning_rateğŸ’¯ ğŸ‡

      X â¡ï¸ğŸ– ğŸ†• input
      ğŸ†•ğŸ¨ğŸšğŸ¦‚ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– ğŸ†•forward_values

      ğŸ†• â©â© 0 epochsâ— â¡ï¸  num_epochs
      ğŸ†• â©â© 0 ğŸ” Wâ— â— â¡ï¸  range_W

      ğŸ”‚ e ğŸ¡ num_epochsâ—ï¸ğŸ‡
         ğŸ˜€ ğŸª ğŸ”¤Epoche ğŸ”¤ ğŸ”¡e 10â—ğŸªâ—

         X â¡ï¸ğŸ– input
         ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input

         ğŸ†•ğŸ¨ğŸšğŸ¦‚ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– forward_values

         ğŸ» forward_values ğŸ†•ğŸ¦‚ğŸ†• ğŸğŸ‡ğŸ 7 7â— ğŸğŸ‡ğŸ 7 7â— inputâ—â—

         ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
            ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— â¡ï¸ mul
            ğŸ‹ğŸ‡ğŸ mul ğŸ½ b iâ—â— â¡ï¸ add
            ğŸ“¸ğŸ‡ğŸ addâ— â¡ï¸ ğŸ–input

            ğŸ» forward_values ğŸ†•ğŸ¦‚ğŸ†• mul add inputâ—ï¸â—ï¸
         ğŸ‰

         ğŸ’­ Calculate derivative of MSE
         ğŸ‘­ğŸ‡ğŸ ğŸ¦ğŸ½ forward_values ğŸ”forward_valuesâ—â–1â—â—ğŸ”ğŸ‡ğŸyâ—â— â¡ï¸ ğŸ– ğŸ†•dmse

         ğŸ†• â©â© 0 ğŸ”forward_valuesâ— â— â¡ï¸  layers

         ğŸ’­ Transform range to list and reverse
         ğŸ†•ğŸ¨ğŸšğŸ”¢ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– ğŸ†•layers_list
         ğŸ”‚ i ğŸ¡ layersâ—ï¸ğŸ‡
            ğŸ» layers_list iâ—
         ğŸ‰

         ğŸ¨ layers_list 0â—
         ğŸ®ğŸ‡ğŸ layers_listâ— â¡ï¸ layers_reversed

         ğŸ”‚ layer ğŸ¡ layers_reversedâ—ï¸ğŸ‡
            ğŸ’­ Derivative of activation function
            ğŸğŸ“·ğŸ‡ğŸ dmseâ—â—â¡ï¸ dmse_array_shape

            ğŸ ğŸğŸ½ forward_values layerâ—â—â— â¡ï¸ forward_values_array_shape

            ğŸˆğŸ‡ğŸ ğŸğŸ½ forward_values layerâ—â— ğŸ“·ğŸ‡ğŸ dmseâ— â— â¡ï¸ dadd

            ğŸ’­ Backward pass add
            ğŸ ğŸ• ğŸ¢ğŸ½ forward_values layerâ—â— ğŸ½ b layerâ–1â— daddâ— â¡ï¸ back_add
            ğŸ¬ back_addâ— â¡ï¸ db
            ğŸ¦ˆ back_addâ— â¡ï¸ dmul

            ğŸ’­ Backward pass mul
            ğŸ¡ğŸ• ğŸ½ W layerâ–1â— ğŸ¦ğŸ½ forward_values layerâ–1â—â— dmulâ— â¡ï¸  back_mul
            ğŸ¬ back_mulâ— â¡ï¸ dW
            ğŸ¦ˆ back_mulâ— â¡ï¸ ğŸ– dmse

            ğŸ’­ Gradient descent parameter update
            ğŸ“ğŸ‡ğŸ ğŸ½ b layerâ–1â— ğŸ¥ğŸ‡ğŸ db ğŸ”‹learning_rateâ—â—â— â¡ï¸ ğŸ½ b layerâ–1â—
            ğŸ“ğŸ‡ğŸ ğŸ½ W layerâ–1â— ğŸ¥ğŸ‡ğŸ dW ğŸ”‹learning_rateâ—â—â— â¡ï¸ ğŸ½ W layerâ–1â—
         ğŸ‰

         ğŸ’­ Calculate loss after each epoch
         ğŸ¦–ğŸ• X yâ— â¡ï¸ loss_array
         ğŸ˜€ğŸ”¤MSE: ğŸ”¤â—
         ğŸ“  loss_arrayâ—
      ğŸ‰
   ğŸ‰


   ğŸ’­ Backward pass through multiply gate
   â— ğŸ¡ WğŸ XğŸ dZğŸ â¡ï¸ ğŸ¦‘ ğŸ‡
      ğŸ Wâ—â¡ï¸ W_array_shape
      ğŸ Xâ—â¡ï¸ X_array_shape
      ğŸ dZâ—â¡ï¸ dZ_array_shape

      ğŸ¥ğŸ‡ğŸ ğŸ”ğŸ‡ğŸ Xâ—dZâ— â¡ï¸ dW
      ğŸ¥ğŸ‡ğŸ dZ ğŸ”ğŸ‡ğŸ Wâ—â— â¡ï¸ dX

      â†©ï¸ ğŸ†•ğŸ¦‘ğŸ†• dW dXâ—
   ğŸ‰

   ğŸ’­ Backward pass through add gate
   â— ğŸ  XğŸ bğŸ dZğŸ â¡ï¸ ğŸ¦‘ ğŸ‡
      ğŸ’­ Get array shapes
      ğŸ Xâ— â¡ï¸ array_shape_X
      ğŸ dZâ— â¡ï¸ array_shape_dZ

      ğŸ’­ Get array with 1's
      ğŸ¥ªğŸ‡ğŸ ğŸ½ array_shape_X 0â— ğŸ½ array_shape_X 1â—â— â¡ï¸ one_like_X

      ğŸˆğŸ‡ğŸ dZ one_like_Xâ— â¡ï¸ dX
      ğŸ¥ğŸ‡ğŸ ğŸ¥ªğŸ‡ğŸ 1 ğŸ½ array_shape_dZ 0â—â— dZâ— â¡ï¸ db

      â†©ï¸ ğŸ†•ğŸ¦‘ğŸ†• db dXâ—
   ğŸ‰
ğŸ‰

ğŸ’­ Value type to hold values while training
ğŸ•Š ğŸ¦‚ ğŸ‡
  ğŸ–ğŸ†• mul ğŸ
  ğŸ–ğŸ†• add ğŸ
  ğŸ–ğŸ†• input ğŸ

   ğŸ†• ğŸ¼ mul ğŸ ğŸ¼ add ğŸ ğŸ¼ input ğŸ ğŸ‡ğŸ‰

   ğŸ’­ Getter for 'mul'
   â—ğŸ¢ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ mul
    ğŸ‰

   ğŸ’­ Getter for 'add'
   â—ğŸ â¡ï¸ ğŸ ğŸ‡
       â†©ï¸ add
     ğŸ‰

   ğŸ’­ Getter for 'input'
    â—ğŸ¦ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ input
    ğŸ‰
ğŸ‰

ğŸ’­ Value type two hold two arrays
ğŸ•Š ğŸ¦‘ ğŸ‡
  ğŸ–ğŸ†• array01 ğŸ
  ğŸ–ğŸ†• array02 ğŸ

   ğŸ†• ğŸ¼ array01 ğŸ ğŸ¼ array02 ğŸ ğŸ‡ğŸ‰

   ğŸ’­ Getter for 'array01'
   â—ğŸ¬ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ array01
    ğŸ‰

   ğŸ’­ Getter for 'array02'
   â—ğŸ¦ˆ â¡ï¸ ğŸ ğŸ‡
       â†©ï¸ array02
    ğŸ‰
ğŸ‰
