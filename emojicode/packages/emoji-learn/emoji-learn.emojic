
ğŸ“¦ numlol ğŸ 

ğŸ’­ Class for neural nets
ğŸ’­ Code for reference: https://github.com/pangolulu/neural-network-from-scratch
ğŸŒ ğŸ‡ ğŸ•¸ ğŸ‡

   ğŸ’­ The weights of the different layers
   ğŸ–ğŸ†• W ğŸ¨ğŸšğŸğŸ†

   ğŸ’­ The biases of the different layers
   ğŸ–ğŸ†• b ğŸ¨ğŸšğŸğŸ†

   ğŸ’­ The dimensions of the various layers
   ğŸ–ğŸ†• layers_dim ğŸ¨ğŸšğŸ”¢ğŸ†

   ğŸ†• ğŸ¼ layers_dim ğŸ¨ğŸšğŸ”¢ğŸ† ğŸ‡
      ğŸ’­ Create empty lists for weights/biases
      ğŸ†•ğŸ¨ğŸšğŸğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– W
      ğŸ†•ğŸ¨ğŸšğŸğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– b
      ğŸ’­ Iterate over all layers and create random weights/biases
      ğŸ†• â©â© 0 ğŸ”layers_dimâ—â–1 â— â¡ï¸  range_layers
      ğŸ”‚ i ğŸ¡ range_layersâ—ï¸ğŸ‡
         ğŸ’­ Create weights for layer
         ğŸ”® ğŸ‡ğŸ ğŸ½ layers_dim iâ— ğŸ½ layers_dim iâ• 1â— -1.0 1.0â— â¡ï¸ random_W
         ğŸ’­ He initialisation
         1.0 â— â›· ğŸ’¯ ğŸ½ layers_dim iâ—â—â— â¡ï¸ he_factor
         ğŸ» W ğŸ¥ ğŸ‡ğŸ random_W he_factorâ—â—

         ğŸ’­ Create biases for layers
         ğŸ”® ğŸ‡ğŸ 1 ğŸ½ layers_dim iâ•1â—  -1.0 1.0â— â¡ï¸ random_b
         ğŸ» b random_bâ—
      ğŸ‰
   ğŸ‰

    ğŸ’­ Calculate loss ("Is this loss?")
   â—ğŸ¦– XğŸ yğŸ â¡ï¸ ğŸ ğŸ‡
      ğŸ†• â©â© 0 ğŸ” Wâ— â— â¡ï¸  range_W
      X â¡ï¸ğŸ– ğŸ†• input
      ğŸ’­ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input
      ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
         ğŸ’­ğŸ¥ğŸ‡ğŸ inputğŸ½ W iâ—â— â¡ï¸ test
         ğŸ‹ğŸ‡ğŸ ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— ğŸ½ b iâ—â— â¡ï¸ raw_output
         ğŸ“¸ğŸ‡ğŸ raw_outputâ— â¡ï¸ ğŸ–input
      ğŸ‰
      â†©ï¸ ğŸ”ğŸ‡ğŸ ğŸ‘¬ğŸ‡ğŸ input yâ—â—
   ğŸ‰

   ğŸ’­ Make prediction
   â—ğŸ¦• XğŸ â¡ï¸ ğŸ ğŸ‡
      ğŸ†• â©â© 0 ğŸ” Wâ— â— â¡ï¸  range_W
      X â¡ï¸ğŸ– ğŸ†• input
      ğŸ’­ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input
      ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
         ğŸ‹ğŸ‡ğŸ ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— ğŸ½ b iâ—â— â¡ï¸ raw_output
         ğŸ“¸ğŸ‡ğŸ raw_outputâ— â¡ï¸ ğŸ–input
      ğŸ‰
      â†©ï¸ ğŸ”ğŸ‡ğŸ inputâ—
   ğŸ‰

   ğŸ’­ Train the net
   â—ğŸ¦„ XğŸ yğŸ epochsğŸ”¢ learning_rateğŸ’¯ ğŸ‡
      ğŸ Xâ— â¡ï¸ X_array
      ğŸ yâ— â¡ï¸ y_array
      ğŸ†•ğŸğŸ†•ğŸ¨ğŸ½ X_array 0â—ğŸ†â— â¡ï¸ğŸ– ğŸ†• input

      ğŸ†•ğŸ¨ğŸšğŸ¦‚ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– ğŸ†•forward_values

      ğŸ†• â©â© 0 epochsâ— â¡ï¸  num_epochs
      ğŸ†• â©â© 0 ğŸ” X_arrayâ—â— â¡ï¸  num_samples
      ğŸ†• â©â© 0 ğŸ” Wâ—â— â¡ï¸  range_W

      ğŸ”‚ e ğŸ¡ num_epochsâ—ï¸ğŸ‡
         ğŸ˜€ ğŸª ğŸ”¤Epoche ğŸ”¤ ğŸ”¡e 10â—ğŸªâ—

         ğŸ’­ Iterate over all samples
         ğŸ”‚ num_sample ğŸ¡ num_samplesâ—ï¸ğŸ‡
           ğŸ†•ğŸğŸ†•ğŸ¨ğŸ½ X_array num_sampleâ—ğŸ†â— â¡ï¸ğŸ– input
           ğŸ’­ğŸ”ğŸ‡ğŸ inputâ— â¡ï¸ğŸ– input

           ğŸ†•ğŸ¨ğŸšğŸ¦‚ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– forward_values

           ğŸ» forward_values ğŸ†•ğŸ¦‚ğŸ†• ğŸğŸ‡ğŸ 1 1â— ğŸğŸ‡ğŸ 1 1â— inputâ—â—

           ğŸ”‚ i ğŸ¡ range_Wâ—ï¸ğŸ‡
              ğŸ¥ğŸ‡ğŸ input ğŸ½ W iâ—â— â¡ï¸ mul
              ğŸ‹ğŸ‡ğŸ mul ğŸ½ b iâ—â— â¡ï¸ add
              ğŸ“¸ğŸ‡ğŸ addâ— â¡ï¸ ğŸ–input

              ğŸ» forward_values ğŸ†•ğŸ¦‚ğŸ†• mul add inputâ—ï¸â—ï¸
           ğŸ‰

           ğŸ’­ Calculate derivative of MSE
           ğŸ‘­ğŸ‡ğŸ ğŸ¦ğŸ½ forward_values ğŸ”forward_valuesâ—â–1â—â—ğŸ†•ğŸğŸ†•ğŸ¨ğŸ½ y_array num_sampleâ—ğŸ†â—â— â¡ï¸ ğŸ– ğŸ†•dmse


           ğŸ†• â©â© 0 ğŸ”layers_dimâ— â— â¡ï¸  layers

           ğŸ’­ Transform range to list and reverse
           ğŸ†•ğŸ¨ğŸšğŸ”¢ğŸ†ğŸ¸â—ï¸ â¡ï¸ğŸ– ğŸ†•layers_list
           ğŸ”‚ i ğŸ¡ layersâ—ï¸ğŸ‡
              ğŸ» layers_list iâ—
           ğŸ‰

           ğŸ¨ layers_list 0â—
           ğŸ®ğŸ‡ğŸ layers_listâ— â¡ï¸ layers_reversed

           ğŸ’­ğŸ˜€ğŸ”¤Layers reversedğŸ”¤â—
           ğŸ’­ğŸ˜€ğŸ“  ğŸ†•ğŸğŸ†• ğŸ¨layers_reversedğŸ†â—â—â—
           ğŸ’­ğŸ˜€ğŸ”¤---------------ğŸ”¤â—

           ğŸ”‚ layer ğŸ¡ layers_reversedâ—ï¸ğŸ‡
              ğŸ’­ Derivative of activation function
              ğŸğŸ“·ğŸ‡ğŸ dmseâ—â—â¡ï¸ dmse_array_shape

              ğŸ ğŸğŸ½ forward_values layerâ—â—â— â¡ï¸ forward_values_array_shape

              ğŸˆğŸ‡ğŸ ğŸ“·ğŸ‡ğŸ ğŸğŸ½ forward_values layerâ—â—â— dmseâ— â¡ï¸ dadd

              ğŸ’­ğŸ˜€ğŸ”¤daddğŸ”¤â—
              ğŸ’­ğŸ“  dadd â—

              ğŸ’­ Backward pass add
              ğŸ ğŸ• ğŸ¢ğŸ½ forward_values layerâ—â— ğŸ½ b layerâ–1â— daddâ— â¡ï¸ back_add
              ğŸ¬ back_addâ— â¡ï¸ db
              ğŸ¦ˆ back_addâ— â¡ï¸ dmul

              ğŸ’­ğŸ˜€ğŸ”¤dmulğŸ”¤â—
              ğŸ’­ğŸ“  dmul â—

              ğŸ’­ Backward pass mul
              ğŸ¡ğŸ• ğŸ½ W layerâ–1â— ğŸ¦ğŸ½ forward_values layerâ–1â—â— dmulâ— â¡ï¸  back_mul
              ğŸ¬ back_mulâ— â¡ï¸ dW
              ğŸ¦ˆ back_mulâ— â¡ï¸ ğŸ– dmse

              ğŸ’­ Gradient descent parameter update
              ğŸ’­ğŸ˜€ğŸ”¤db: ğŸ”¤â—
              ğŸ’­ğŸ“  dbâ—
              ğŸ’­ğŸ˜€ğŸ”¤b: ğŸ”¤â—
              ğŸ’­ğŸ“  ğŸ½ b 1â—â—
              ğŸ’­ğŸ˜€ğŸ”¤dWğŸ”¤â—
              ğŸ’­ğŸ“  dW â—
              ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
              ğŸ’­ğŸ˜€ğŸ”¤W 0ğŸ”¤â—
              ğŸ’­ğŸ“  ğŸ½ W 0â—â—
              ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
              ğŸ’­ğŸ˜€ğŸ”¤W 1ğŸ”¤â—
              ğŸ’­ğŸ“  ğŸ½ W 1â—â—
              ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
              ğŸ’­ğŸ˜€ğŸ”¤dmse: ğŸ”¤â—
              ğŸ’­ğŸ“  dmseâ—
              ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
              ğŸ“ğŸ‡ğŸ ğŸ½ b layerâ–1â— ğŸ¥ğŸ‡ğŸ db learning_rateâ—â— â¡ï¸ ğŸ½ b layerâ–1â—
              ğŸ“ğŸ‡ğŸ ğŸ½ W layerâ–1â— ğŸ¥ğŸ‡ğŸ dW learning_rateâ—â— â¡ï¸ ğŸ½ W layerâ–1â—

              ğŸ’­ğŸ˜€ğŸ”¤b: ğŸ”¤â—
              ğŸ’­ğŸ“  ğŸ½ b 1â—â—
           ğŸ‰

         ğŸ‰

         ğŸ’­ Calculate loss after each epoch
         ğŸ¦–ğŸ• ğŸ†•ğŸğŸ†•ğŸ¨ğŸ½ X_array 0â—ğŸ†â— ğŸ†•ğŸğŸ†•ğŸ¨ğŸ½ y_array 0â—ğŸ†â—â— â¡ï¸ loss_array
         ğŸ˜€ğŸ”¤MSE: ğŸ”¤â—
         ğŸ“  loss_arrayâ—
         ğŸ˜€ğŸ”¤ğŸ”¤â—
      ğŸ‰
   ğŸ‰


   ğŸ’­ Backward pass through multiply gate
   â— ğŸ¡ WğŸ XğŸ dZğŸ â¡ï¸ ğŸ¦‘ ğŸ‡
      ğŸ Wâ—â¡ï¸ W_array_shape
      ğŸ Xâ—â¡ï¸ X_array_shape
      ğŸ dZâ—â¡ï¸ dZ_array_shape

      ğŸ¥ğŸ‡ğŸ ğŸ”ğŸ‡ğŸ Xâ—dZâ— â¡ï¸ dW
      ğŸ¥ğŸ‡ğŸ dZ ğŸ”ğŸ‡ğŸ Wâ—â— â¡ï¸ dX

      ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
      ğŸ’­ğŸ˜€ğŸ”¤X: ğŸ”¤â—
      ğŸ’­ğŸ“  Xâ—

      ğŸ’­ğŸ˜€ğŸ”¤-----------ğŸ”¤â—
      ğŸ’­ğŸ˜€ğŸ”¤dZ: ğŸ”¤â—
      ğŸ’­ğŸ“  dZâ—

      â†©ï¸ ğŸ†•ğŸ¦‘ğŸ†• dW dXâ—
   ğŸ‰

   ğŸ’­ Backward pass through add gate
   â— ğŸ  XğŸ bğŸ dZğŸ â¡ï¸ ğŸ¦‘ ğŸ‡
      ğŸ’­ Get array shapes
      ğŸ Xâ— â¡ï¸ array_shape_X
      ğŸ dZâ— â¡ï¸ array_shape_dZ

      ğŸ’­ Get array with 1's
      ğŸ¥ªğŸ‡ğŸ ğŸ½ array_shape_X 0â— ğŸ½ array_shape_X 1â—â— â¡ï¸ one_like_X

      ğŸˆğŸ‡ğŸ dZ one_like_Xâ— â¡ï¸ dX
      ğŸ¥ğŸ‡ğŸ ğŸ¥ªğŸ‡ğŸ 1 ğŸ½ array_shape_dZ 0â—â— dZâ— â¡ï¸ db

      â†©ï¸ ğŸ†•ğŸ¦‘ğŸ†• db dXâ—
   ğŸ‰

   ğŸ’­ Read data from file
   ğŸ’­ features --> scaled
   ğŸ’­ labels   --> one-hot encoded
   ğŸ’­ Returns value type with X and y
   ğŸ‡â— ğŸ¦‹ filepathğŸ”¡  â¡ï¸ ğŸ¦‘ğŸ‡
      ğŸ—„ ğŸ‡ğŸ filepath ğŸ‘â— â¡ï¸ file_array
      ğŸ”ğŸ‡ğŸ file_arrayâ— â¡ï¸ transposed_array

      ğŸ¥—ğŸ‡ğŸ transposed_array ğŸ¤ ğŸ‡ğŸ ğŸ”ğŸtransposed_arrayâ—â—â–1 â— â— â¡ï¸ raw_X
      ğŸ¥—ğŸ‡ğŸ transposed_array ğŸ¨ğŸ”ğŸtransposed_arrayâ—â—â–1ğŸ†â— â¡ï¸ raw_y

      ğŸ”ğŸ‡ğŸ raw_Xâ— â¡ï¸ transposed_raw_X
      ğŸ”ğŸ‡ğŸ raw_yâ— â¡ï¸ transposed_raw_y

      ğŸ’­ Scale the features
      ğŸ”¥ğŸ‡ğŸ transposed_raw_yâ— â¡ï¸ one_hot_y

      ğŸ’­ One-hot encoding of labels
      ğŸ¥™ğŸ‡ğŸ transposed_raw_X 1â— â¡ï¸ scaled_X

      â†©ï¸ ğŸ†•ğŸ¦‘ğŸ†• scaled_X one_hot_yâ—
   ğŸ‰

ğŸ‰


ğŸ’­ Value type to hold values while training
ğŸ•Š ğŸ¦‚ ğŸ‡
  ğŸ–ğŸ†• mul ğŸ
  ğŸ–ğŸ†• add ğŸ
  ğŸ–ğŸ†• input ğŸ

   ğŸ†• ğŸ¼ mul ğŸ ğŸ¼ add ğŸ ğŸ¼ input ğŸ ğŸ‡ğŸ‰

   ğŸ’­ Getter for 'mul'
   â—ğŸ¢ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ mul
    ğŸ‰

   ğŸ’­ Getter for 'add'
   â—ğŸ â¡ï¸ ğŸ ğŸ‡
       â†©ï¸ add
     ğŸ‰

   ğŸ’­ Getter for 'input'
    â—ğŸ¦ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ input
    ğŸ‰
ğŸ‰

ğŸ’­ Value type two hold two arrays
ğŸ•Š ğŸ¦‘ ğŸ‡
  ğŸ–ğŸ†• array01 ğŸ
  ğŸ–ğŸ†• array02 ğŸ

   ğŸ†• ğŸ¼ array01 ğŸ ğŸ¼ array02 ğŸ ğŸ‡ğŸ‰

   ğŸ’­ Getter for 'array01'
   â—ğŸ¬ â¡ï¸ ğŸ ğŸ‡
      â†©ï¸ array01
    ğŸ‰

   ğŸ’­ Getter for 'array02'
   â—ğŸ¦ˆ â¡ï¸ ğŸ ğŸ‡
       â†©ï¸ array02
    ğŸ‰
ğŸ‰
